{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durgesh846/COLORIZATION-OF-BLACK-WHITE-IMAGE-USING-MACHINE-LEARNING/blob/master/Copy_of_FINAL_YEAR_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26uIl2XGkgcN"
      },
      "source": [
        "\n",
        "# **Image Colorization With GANs**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyngrok"
      ],
      "metadata": {
        "id": "7xweA2b8nPxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "e50FOin5ngZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_no = 5000"
      ],
      "metadata": {
        "id": "lFjk9D0Vnrq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, send_file, make_response\n",
        "from PIL import Image\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = Flask(__name__)\n",
        "ngrok.set_auth_token(\"2PosU2T1Ustq6Y5WBcDynNPjlPI_2Uqerhz5kbJCeaf9T7EdM\")\n",
        "public_url = ngrok.connect(port_no).public_url\n",
        "\n",
        "\n",
        "@app.route('/process-image', methods=['POST'])\n",
        "def process_image():\n",
        "\n",
        "    # Get the image file from the request\n",
        "    image_file = request.files['image']\n",
        "\n",
        "    # Open the image file\n",
        "    image = Image.open(image_file)\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((200, 200))\n",
        "\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Load the generator model\n",
        "    generator = tf.keras.models.load_model('/content/drive/MyDrive/mymodel/generator.h5')\n",
        "\n",
        "    # Load the grayscale image that you want to colorize\n",
        "\n",
        "    # Convert the PIL image to a NumPy array\n",
        "    np_image = np.array(image)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    grayscale_img = cv2.cvtColor(np_image, cv2.COLOR_RGB2GRAY)\n",
        "    grayscale_img = cv2.resize(grayscale_img, (120, 120))\n",
        "    grayscale_img = np.expand_dims(grayscale_img, axis=-1)\n",
        "    grayscale_img = grayscale_img.astype(np.float32) / 255.0\n",
        "\n",
        "    # Generate a new colored image from the grayscale input\n",
        "    colored_img = generator.predict(np.array([grayscale_img]))\n",
        "\n",
        "    # Save the processed image to a buffer\n",
        "    buffer = io.BytesIO()\n",
        "\n",
        "    colored_img = colored_img.squeeze() * 255.0\n",
        "    colored_img = np.clip(colored_img, 0, 255).astype(np.uint8)\n",
        "    Image.fromarray(colored_img).save(buffer, format='JPEG')\n",
        "\n",
        "\n",
        "    # Return the processed image as a file\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Create a custom response object\n",
        "    response = make_response(buffer.getvalue())\n",
        "    response.headers['Content-Type'] = 'image/jpeg'\n",
        "\n",
        "    # Add the Access-Control-Allow-Origin header to allow requests from any domain\n",
        "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "print(f\"To access the Global link please click {public_url}\")\n",
        "app.run(port=port_no)\n"
      ],
      "metadata": {
        "id": "NWs6iq4DJfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4-cYBxxmjK4"
      },
      "source": [
        "\n",
        "## **1. Downloading and Processing the data**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K-5UE4qF1XSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLbLh8Y2od4P"
      },
      "source": [
        "\n",
        "We'll now parse the images ( RGB images to be precise ) one by one, and transform each one to a grayscale image using PIL's `.convert( 'L' )` method. So our dataset will have samples of $( \\ grayscale \\ image \\ , \\ RGB \\ image \\ )$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Y9h0CzfL91"
      },
      "source": [
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# The batch size we'll use for training\n",
        "batch_size = 64\n",
        "\n",
        "# Size of the image required to train our model\n",
        "img_size = 120\n",
        "\n",
        "# These many images will be used from the data archive\n",
        "dataset_split = 2500\n",
        "\n",
        "master_dir = '/content/drive/MyDrive/data'\n",
        "x = []\n",
        "y = []\n",
        "for image_file in os.listdir( master_dir )[ 0 : dataset_split ]:\n",
        "    rgb_image = Image.open( os.path.join( master_dir , image_file ) ).resize( ( img_size , img_size ) )\n",
        "    # Normalize the RGB image array\n",
        "    rgb_img_array = (np.asarray( rgb_image ) ) / 255\n",
        "    gray_image = rgb_image.convert( 'L' )\n",
        "    # Normalize the grayscale image array\n",
        "    gray_img_array = ( np.asarray( gray_image ).reshape( ( img_size , img_size , 1 ) ) ) / 255\n",
        "    # Append both the image arrays\n",
        "    x.append( gray_img_array )\n",
        "    y.append( rgb_img_array )\n",
        "\n",
        "# Train-test splitting\n",
        "train_x, test_x, train_y, test_y = train_test_split( np.array(x) , np.array(y) , test_size=0.1 )\n",
        "\n",
        "# Construct tf.data.Dataset object\n",
        "dataset = tf.data.Dataset.from_tensor_slices( ( train_x , train_y ) )\n",
        "dataset = dataset.batch( batch_size )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euCdKKt_r4wg"
      },
      "source": [
        "\n",
        "## **2. The GAN**\n",
        "First, we'll implement the generator then the discriminator and finally the loss functions required by both of them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQUjuTsJsbwK"
      },
      "source": [
        "\n",
        "### **A. Generator** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIZEoRpB03YS"
      },
      "source": [
        "\n",
        "def get_generator_model():\n",
        "\n",
        "    inputs = tf.keras.layers.Input( shape=( img_size , img_size , 1 ) )\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D( 16 , kernel_size=( 5 , 5 ) , strides=1 )( inputs )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D( 32 , kernel_size=( 5 , 5 ) , strides=1)( conv1 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "\n",
        "    bottleneck = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' , padding='same' )( conv3 )\n",
        "\n",
        "    concat_1 = tf.keras.layers.Concatenate()( [ bottleneck , conv3 ] )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_1 )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( conv_up_3 )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_3 )\n",
        "\n",
        "    concat_2 = tf.keras.layers.Concatenate()( [ conv_up_3 , conv2 ] )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_2 )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( conv_up_2 )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_2 )\n",
        "\n",
        "    concat_3 = tf.keras.layers.Concatenate()( [ conv_up_2 , conv1 ] )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( concat_3 )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( conv_up_1 )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 3 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu')( conv_up_1 )\n",
        "\n",
        "    model = tf.keras.models.Model( inputs , conv_up_1 )\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHPoEyuiujv1"
      },
      "source": [
        "\n",
        "### **B. Discriminator**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MN4QA16xSbi"
      },
      "source": [
        "\n",
        "def get_discriminator_model():\n",
        "    layers = [\n",
        "        tf.keras.layers.Conv2D( 32 , kernel_size=( 7 , 7 ) , strides=1 , activation='relu' , input_shape=( 120 , 120 , 3 ) ),\n",
        "        tf.keras.layers.Conv2D( 32 , kernel_size=( 7, 7 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense( 512, activation='relu'  )  ,\n",
        "        tf.keras.layers.Dense( 128 , activation='relu' ) ,\n",
        "        tf.keras.layers.Dense( 16 , activation='relu' ) ,\n",
        "        tf.keras.layers.Dense( 1 , activation='sigmoid' ) \n",
        "    ]\n",
        "    model = tf.keras.models.Sequential( layers )\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CER2JcDt08G8"
      },
      "source": [
        "\n",
        "### **C. Loss Functions**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXLB6fR4fFQP"
      },
      "source": [
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output , real_y):\n",
        "    real_y = tf.cast( real_y , 'float32' )\n",
        "    return mse( fake_output , real_y )\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "\n",
        "generator = get_generator_model()\n",
        "discriminator = get_discriminator_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgwdqAHd_ar"
      },
      "source": [
        "\n",
        "## **3. Training The GAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxUEQpDmgoLa"
      },
      "source": [
        "\n",
        "@tf.function\n",
        "def train_step( input_x , real_y ):\n",
        "   \n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate an image -> G( x )\n",
        "        generated_images = generator( input_x , training=True)\n",
        "        # Probability that the given image is real -> D( x )\n",
        "        real_output = discriminator( real_y, training=True)\n",
        "        # Probability that the given image is the one generated -> D( G( x ) )\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "        \n",
        "        # L2 Loss -> || y - G(x) ||^2\n",
        "        gen_loss = generator_loss( generated_images , real_y )\n",
        "        # Log loss for the discriminator\n",
        "        disc_loss = discriminator_loss( real_output, generated_output )\n",
        "    \n",
        "    #tf.keras.backend.print_tensor( tf.keras.backend.mean( gen_loss ) )\n",
        "    #tf.keras.backend.print_tensor( gen_loss + disc_loss )\n",
        "\n",
        "    # Compute the gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Optimize with Adam\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoQ9H3Iwfa_x"
      },
      "source": [
        "\n",
        "\n",
        "**To start the training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Lbh5rvfaik"
      },
      "source": [
        "\n",
        "num_epochs = 25\n",
        "\n",
        "for e in range( num_epochs ):\n",
        "    print( e )\n",
        "    for ( x , y ) in dataset:\n",
        "        # Here ( x , y ) represents a batch from our training dataset.\n",
        "        print( x.shape )\n",
        "        train_step( x , y )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynE-Hp6lWeZT"
      },
      "source": [
        "\n",
        "## **4. Results**\n",
        "\n",
        "We plot an image to see the results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKixh637SIYh"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y = generator( test_x[ 0 : 25 ] ).numpy()\n",
        "i = 14\n",
        "image = Image.fromarray( ( y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "image = np.asarray( image )\n",
        "plt.imshow( image )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiFpByHFbCfi"
      },
      "source": [
        "\n",
        "image = Image.fromarray( ( test_y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "plt.imshow( image )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmHPhHpbYhZU"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow( test_x[i].reshape((120,120)) , cmap='gray' )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Model"
      ],
      "metadata": {
        "id": "XE7QlGqzrrWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('/content/drive/MyDrive/mymodel/generator.h5')\n",
        "discriminator.save('/content/drive/MyDrive/mymodel/discriminator.h5')"
      ],
      "metadata": {
        "id": "JGfS8OcDeKkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the model"
      ],
      "metadata": {
        "id": "8OfjKY56r1sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "generator = tf.keras.models.load_model('/content/drive/MyDrive/mymodel/generator.h5')\n",
        "discriminator = tf.keras.models.load_model('/content/drive/MyDrive/mymodel/discriminator.h5')"
      ],
      "metadata": {
        "id": "KfCaRJG6hkkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating the new coloured Image"
      ],
      "metadata": {
        "id": "G4EKgpLDr5oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Load the generator model\n",
        "generator = tf.keras.models.load_model('/content/drive/MyDrive/mymodel/generator.h5')\n",
        "\n",
        "# Load the grayscale image that you want to colorize\n",
        "grayscale_img = cv2.imread('/content/drive/MyDrive/newData/20057.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "grayscale_img = cv2.resize(grayscale_img, (120, 120))\n",
        "grayscale_img = np.expand_dims(grayscale_img, axis=-1)\n",
        "grayscale_img = grayscale_img.astype(np.float32)/255.0\n",
        "\n",
        "# Generate a new colored image from the grayscale input\n",
        "colored_img = generator.predict(np.array([grayscale_img]))\n",
        "\n"
      ],
      "metadata": {
        "id": "M7AC9oGFoFpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the generated coloured image"
      ],
      "metadata": {
        "id": "7oFCNFgcsCfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert BGR image to RGB\n",
        "colored_img = cv2.cvtColor(colored_img[0], cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(colored_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Eol8Bddoojy_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}